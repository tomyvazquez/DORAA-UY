{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Julia version info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.8.1\n",
      "Commit afb6c60d69a (2022-09-06 15:09 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-linux-gnu)\n",
      "      Ubuntu 22.04.5 LTS\n",
      "  uname: Linux 6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2 x86_64 x86_64\n",
      "  CPU: 13th Gen Intel(R) Core(TM) i5-13400F: \n",
      "                 speed         user         nice          sys         idle          irq\n",
      "       #1-16  4607 MHz     165696 s         59 s      17751 s   97094905 s          0 s\n",
      "  Memory: 62.63290023803711 GB (46062.7421875 MB free)\n",
      "  Uptime: 608048.65 sec\n",
      "  Load Avg:  0.48  0.86  0.83\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-13.0.1 (ORCJIT, goldmont)\n",
      "  Threads: 1 on 16 virtual cores\n",
      "Environment:\n",
      "  HOME = /home/nacho\n",
      "  PATH = /home/nacho/miniconda3/envs/proy/bin:/home/nacho/.vscode-server/cli/servers/Stable-384ff7382de624fb94dbaf6da11977bba1ecd427/server/bin/remote-cli:/home/nacho/.local/bin:/home/nacho/miniconda3/envs/proy/bin:/home/nacho/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/nacho/julia-1.8.1/bin\n",
      "  TERM = xterm-color\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Julia executable: /home/nacho/julia-1.8.1/bin/julia\n",
      "[ Info: Trying to import PyCall...\n",
      "┌ Warning: PyCall is already installed.  However, you may have trouble using\n",
      "│ this Python executable because it is statically linked to libpython.\n",
      "│ \n",
      "│ For more information, see:\n",
      "│     https://pyjulia.readthedocs.io/en/latest/troubleshooting.html\n",
      "│ \n",
      "│ Python executable:\n",
      "│     /home/nacho/miniconda3/envs/proy/bin/python\n",
      "│ Julia executable:\n",
      "│     /home/nacho/julia-1.8.1/bin/julia\n",
      "└ @ Main ~/miniconda3/envs/proy/lib/python3.12/site-packages/julia/install.jl:90\n"
     ]
    }
   ],
   "source": [
    "# Generales\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandapower as pp\n",
    "import numpy as np\n",
    "import julia\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# julia\n",
    "julia.install()\n",
    "from julia.api import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "\n",
    "# Internos\n",
    "sys.path.append(os.path.abspath('../entrenamiento'))\n",
    "from src.arquitecturas import GNNUnsupervised, FCNNUnsupervised\n",
    "from src.Data_loader import load_net, load_data\n",
    "from src.utils import get_Ybus, get_Yline, init_lamdas,get_line\n",
    "from src.Loss import my_loss, get_max_min_values,cost_ploss, constraint_violation_power_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levantar Red electrica, Predictor y Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/red118/train/input.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m min_vector, max_vector \u001b[38;5;241m=\u001b[39m get_max_min_values(net,device)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Levantar Datos\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m train_loader, val_loader, test_loader, norm_x \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# train_loader, val_loader, test_loader = load_data(cfg.data.data_path, cfg.training.batch_size, False, cfg.data.red,device)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m train_loader_unorm, val_loader_unorm, test_loader_unorm, _ \u001b[38;5;241m=\u001b[39m load_data(cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdata_path, cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28;01mFalse\u001b[39;00m, cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mred,device)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Levantar predictor\u001b[39;00m\n",
      "File \u001b[0;32m~/DORAA-UY/no-supervisado/IEEE/entrenamiento/src/Data_loader.py:72\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_path, batch_size, normalize_X, red, device)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(data_path, batch_size, normalize_X, red, device):\n\u001b[0;32m---> 72\u001b[0m     X_tensor_train \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/red\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mred\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/train/input.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)        \n\u001b[1;32m     73\u001b[0m     X_tensor_val \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mload(data_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/red\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/val/input.npy\u001b[39m\u001b[38;5;124m'\u001b[39m) ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)        \n\u001b[1;32m     74\u001b[0m     X_tensor_test \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mload(data_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/red\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/input.npy\u001b[39m\u001b[38;5;124m'\u001b[39m) ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)        \n",
      "File \u001b[0;32m~/miniconda3/envs/proy/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/red118/train/input.npy'"
     ]
    }
   ],
   "source": [
    "red = \"118\" # \"118\" o \"30\"\n",
    "arq = \"GNN\" # \"GNN\" o \"FCNN\"\n",
    "\n",
    "# Levantar CFG\n",
    "entrenamiento = \"best\"\n",
    "cfg = OmegaConf.load(f\"./runs/{red}/{arq}/\" + entrenamiento + \"/config.yaml\")\n",
    "weights_dir = f\"./runs/{red}/{arq}/\" + entrenamiento +  \"/weights/best_model.pt\"\n",
    "\n",
    "# Settear GPU\n",
    "torch.manual_seed(cfg.training.seed)\n",
    "device = cfg.training.device\n",
    "\n",
    "# Levantar red electrica\n",
    "edge_index, edge_weights, net = load_net(cfg.data.red,cfg.data.red_path,device)\n",
    "\n",
    "if red == \"30\":\n",
    "    net.line[\"max_loading_percent\"] *= 1.1\n",
    "    net.ext_grid[\"min_q_mvar\"] = -50\n",
    "else:\n",
    "    net.trafo.tap_pos = 0.0\n",
    "    net.bus.max_vm_pu = 1.1\n",
    "    net.bus.min_vm_pu = 0.9\n",
    "    net.line.max_i_ka /= 20\n",
    "\n",
    "pp.runpp(net)\n",
    "Y_bus = get_Ybus(net,device)\n",
    "Y_line = get_Yline(net,device)\n",
    "line = get_line(net, device)\n",
    "min_vector, max_vector = get_max_min_values(net,device)\n",
    "\n",
    "# Levantar Datos\n",
    "\n",
    "train_loader, val_loader, test_loader, norm_x = load_data(cfg.data.data_path, cfg.training.batch_size, cfg.data.normalize_X, cfg.data.red, device)# train_loader, val_loader, test_loader = load_data(cfg.data.data_path, cfg.training.batch_size, False, cfg.data.red,device)\n",
    "train_loader_unorm, val_loader_unorm, test_loader_unorm, _ = load_data(cfg.data.data_path, cfg.training.batch_size, False, cfg.data.red,device)\n",
    "\n",
    "# Levantar predictor\n",
    "num_layers = len(cfg.model.layers) - 1\n",
    "num_nodes = len(net.bus)\n",
    "try:\n",
    "    a = cfg.model.model\n",
    "except:\n",
    "    cfg.model.model = \"GNN\"\n",
    "if cfg.model.model==\"GNN\":\n",
    "        model = GNNUnsupervised(cfg.model.layers, edge_index, edge_weights, num_layers, cfg.model.K, min_vector, max_vector, num_nodes,cfg.model.dropout, batch_norm=cfg.training.batch_norm, use_edge_weights=cfg.training.use_edge_weights).to(device)\n",
    "elif cfg.model.model==\"FCNN\":\n",
    "    cfg.model.K = -1\n",
    "    model = FCNNUnsupervised(cfg.model.layers, edge_index, Y_bus, num_layers, cfg.model.K, min_vector, max_vector, num_nodes, cfg.model.dropout, batch_norm=cfg.training.batch_norm).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(weights_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir Salidas en Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor_test = torch.Tensor(np.load(f'../data/red{red}/test/vm_pu_opt.npy')).to(device)\n",
    "data_test = TensorDataset( y_tensor_test)\n",
    "test_loader_Y = DataLoader(data_test, batch_size=cfg.training.batch_size,drop_last=True)\n",
    "combined_dataloader = zip(test_loader, test_loader_Y)\n",
    "\n",
    "u_pred = []\n",
    "x_tot = []\n",
    "y_tot = []\n",
    "for input, y in combined_dataloader:\n",
    "    u_pred.append(model(input[0]).detach().cpu().numpy())\n",
    "    y_tot.append(y[0].detach().cpu().numpy())\n",
    "\n",
    "for input in test_loader_unorm:\n",
    "    x_tot.append(input[0].detach().cpu().numpy())\n",
    "\n",
    "# Concatenate in dim 0\n",
    "u_pred = np.concatenate(u_pred, axis=0)\n",
    "y_pred = u_pred[:,:,2][:,:,None]\n",
    "x_tot = np.concatenate(x_tot, axis=0)\n",
    "y_tot = np.concatenate(y_tot, axis=0)\n",
    "y_tot = y_tot[:,:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar desempeño como solucion del ORPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para evaluar pérdias y unfeasiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(net,tol=2e-3, percent_gap=None):\n",
    "    \n",
    "    # METRICA\n",
    "    Y_line_ij = np.asarray(net._ppc[\"internal\"][\"Yf\"].todense())\n",
    "    Y_line_ji = np.asarray(net._ppc[\"internal\"][\"Yt\"].todense())\n",
    "    V_mag = net.res_bus.vm_pu\n",
    "    delta = net.res_bus.va_degree\n",
    "    V = V_mag * np.exp(1j * delta * 2*np.pi/360)\n",
    "    V_lines_to = [V[x] for x in net.line.to_bus] + [V[x] for x in net.trafo.lv_bus]\n",
    "    V_lines_from = [V[x] for x in net.line.from_bus] + [V[x] for x in net.trafo.hv_bus]\n",
    "    ploss = (V_lines_from * np.conj(np.matmul(Y_line_ij,V)) + V_lines_to * np.conj(np.matmul(Y_line_ji,V))).real * net.sn_mva\n",
    "    ploss_cost = ploss.sum()\n",
    "    \n",
    "    \n",
    "    # UNFEASIBILITY\n",
    "    \n",
    "    ## Lineas\n",
    "    max_line = net.line.max_loading_percent.values.copy()\n",
    "    if percent_gap is not None:\n",
    "        max_line = max_line * (1 + percent_gap)\n",
    "    unfeas_line = (net.res_line.loading_percent.values > max_line + tol).sum()\n",
    "    gap_line_max = (net.res_line.loading_percent.values - net.line.max_loading_percent.values - tol)/(net.line.max_loading_percent.values - 0)\n",
    "    gap_line_max = gap_line_max[np.where(gap_line_max > 0)] * 100\n",
    "\n",
    "    ## Trafos\n",
    "    unfeas_trafo = 0\n",
    "    gap_trafo_max = []\n",
    "    if len(net.trafo) > 0:\n",
    "        max_trafo = net.trafo.max_loading_percent.values.copy()\n",
    "        if percent_gap is not None:\n",
    "            max_trafo = max_trafo * (1 + percent_gap)\n",
    "        unfeas_trafo = (net.res_trafo.loading_percent.values > max_trafo + tol).sum()\n",
    "        gap_trafo_max = (net.res_trafo.loading_percent.values - net.trafo.max_loading_percent.values - tol)/(net.trafo.max_loading_percent.values - 0)\n",
    "        gap_trafo_max = gap_trafo_max[np.where(gap_trafo_max > 0)] * 100\n",
    "    else:\n",
    "        unfeas_trafo = 0\n",
    "    \n",
    "    ## Voltajes\n",
    "    max_volt = net.bus.max_vm_pu.values.copy()\n",
    "    min_volt = net.bus.min_vm_pu.values.copy()\n",
    "    if percent_gap is not None:\n",
    "        max_volt +=  percent_gap*(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "        min_volt -= percent_gap*(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "    unfeas_volt = (net.res_bus.vm_pu.values < min_volt - tol).sum() + (net.res_bus.vm_pu.values > max_volt + tol).sum()\n",
    "    gap_volt_max = (net.res_bus.vm_pu.values - net.bus.max_vm_pu.values - tol)/(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "    gap_volt_max = gap_volt_max[np.where(gap_volt_max > 0)] * 100\n",
    "    gap_volt_min = (-net.res_bus.vm_pu.values + net.bus.min_vm_pu.values + tol)/(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "    gap_volt_min = gap_volt_min[np.where(gap_volt_min > 0)] * 100\n",
    "    \n",
    "    ## Q ext grid\n",
    "    max_q_extgrid = net.ext_grid.max_q_mvar.values.astype(float).copy()\n",
    "    min_q_extgrid = net.ext_grid.min_q_mvar.values.astype(float).copy()\n",
    "    if percent_gap is not None:\n",
    "        max_q_extgrid +=  percent_gap*(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "        min_q_extgrid -= percent_gap*(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "    unfeas_q_ext_grid = (net.res_ext_grid.q_mvar.values < min_q_extgrid - tol).sum() + (net.res_ext_grid.q_mvar.values > max_q_extgrid + tol).sum()\n",
    "    gap_q_ext_grid_max = (net.res_ext_grid.q_mvar.values - net.ext_grid.max_q_mvar.values - tol)/(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "    gap_q_ext_grid_max = gap_q_ext_grid_max[np.where(gap_q_ext_grid_max > 0)] * 100\n",
    "    gap_q_ext_grid_min = (-net.res_ext_grid.q_mvar.values + net.ext_grid.min_q_mvar.values + tol)/(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "    gap_q_ext_grid_min = gap_q_ext_grid_min[np.where(gap_q_ext_grid_min > 0)] * 100\n",
    "\n",
    "    # Agregar Todos\n",
    "    gaps_percentages = []\n",
    "    if len(gap_line_max) > 0:\n",
    "        gaps_percentages += list(gap_line_max)\n",
    "    if len(gap_trafo_max) > 0:\n",
    "        gaps_percentages += list(gap_trafo_max)\n",
    "    if len(gap_volt_max) > 0:\n",
    "        gaps_percentages += list(gap_volt_max)\n",
    "    if len(gap_volt_min) > 0:\n",
    "        gaps_percentages += list(gap_volt_min)\n",
    "    if len(gap_q_ext_grid_max) > 0:\n",
    "        gaps_percentages += list(gap_q_ext_grid_max)\n",
    "    if len(gap_q_ext_grid_min) > 0:\n",
    "        gaps_percentages += list(gap_q_ext_grid_min)\n",
    "        \n",
    "    if unfeas_line > 0 or unfeas_trafo > 0 or unfeas_volt > 0 or unfeas_q_ext_grid > 0:\n",
    "        unfeas = True\n",
    "    else:\n",
    "        unfeas = False\n",
    "    return ploss_cost, unfeas, [unfeas_line, unfeas_trafo, unfeas_volt, unfeas_q_ext_grid], gaps_percentages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar la función para datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m gap_percentages_hist_v1 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m percent_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;66;03m## GAPS PARA TOLERANCIA MAXIMA\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(\u001b[43mx_tot\u001b[49m)[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Cargar entradas\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     net\u001b[38;5;241m.\u001b[39mload\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_mw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x_tot[idx,idx_load,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     17\u001b[0m     net\u001b[38;5;241m.\u001b[39mload\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq_mvar\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x_tot[idx,idx_load,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_tot' is not defined"
     ]
    }
   ],
   "source": [
    "idx_gens = net.gen.bus.values.astype(int)\n",
    "idx_load = net.load.bus.values.astype(int)\n",
    "\n",
    "v_cost_hist = []\n",
    "unf_hist = []\n",
    "unf_cont_hist = []\n",
    "gap_percentages_hist_pred = []\n",
    "gap_percentages_hist_opt = []\n",
    "gap_percentages_hist_v1 = []\n",
    "\n",
    "\n",
    "percent_gap = 0.0 ## GAPS PARA TOLERANCIA MAXIMA\n",
    "\n",
    "for idx in range(np.shape(x_tot)[0]):\n",
    "    # Cargar entradas\n",
    "    net.load.loc[:,'p_mw'] = x_tot[idx,idx_load,0]* 100\n",
    "    net.load.loc[:,'q_mvar'] = x_tot[idx,idx_load,1]* 100\n",
    "    net.gen.loc[:,'p_mw'] =  x_tot[idx,idx_gens,2]* 100\n",
    "    \n",
    "    # Cargar solucion predicha\n",
    "    net.gen.vm_pu = y_pred[idx,idx_gens,0]\n",
    "    pp.runpp(net, enforce_q_lims=True)\n",
    "    v_cost_pred, unf_pred, unf_const_pred, gaps_percentages_pred = get_stats(net,percent_gap=percent_gap)\n",
    "\n",
    "    # Cargar solución naive\n",
    "    net.gen.vm_pu = 1\n",
    "    pp.runpp(net, enforce_q_lims=True)\n",
    "    v_cost_v1, unf_v1, unf_const_v1, gaps_percentages_v1  = get_stats(net,percent_gap=percent_gap)\n",
    "    \n",
    "    # Cargar solución óptima\n",
    "    net.gen.vm_pu = y_tot[idx,idx_gens,0]\n",
    "    pp.runpp(net, enforce_q_lims=True)\n",
    "    v_cost_opt, unf_opt, unf_const_opt, gaps_percentages_opt  = get_stats(net,percent_gap=percent_gap)\n",
    "    \n",
    "    # Guardar todo\n",
    "    v_cost_hist.append([v_cost_pred, v_cost_opt,v_cost_v1])\n",
    "    unf_hist.append([unf_pred, unf_opt, unf_v1])\n",
    "    unf_cont_hist.append([unf_const_pred, unf_const_opt, unf_const_v1])\n",
    "    gap_percentages_hist_pred += gaps_percentages_pred\n",
    "    gap_percentages_hist_opt += gaps_percentages_opt\n",
    "    gap_percentages_hist_v1 += gaps_percentages_v1\n",
    "\n",
    "\n",
    "v_cost_hist = np.array(v_cost_hist)\n",
    "unf_hist = np.array(unf_hist)\n",
    "unf_cont_hist = np.array(unf_cont_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de factibles para el óptimo es: 0.96875\n",
      "El porcentaje de factibles para la predicción es: 1.0\n",
      "El porcentaje de factibles para el naive es: 0.9609375\n"
     ]
    }
   ],
   "source": [
    "print(f\"El porcentaje de factibles para el óptimo es: {1 - unf_hist[:,1].mean(axis=0)}\")\n",
    "print(f\"El porcentaje de factibles para la predicción es: {1 - unf_hist[:,0].mean(axis=0)}\")\n",
    "print(f\"El porcentaje de factibles para el naive es: {1 - unf_hist[:,2].mean(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El costo promedio para el óptimo es: 84.82884076595995\n",
      "El costo promedio para la predicción es: 84.05896274886392\n",
      "El costo promedio para el naive es: 95.9575905733169\n"
     ]
    }
   ],
   "source": [
    "print(f\"El costo promedio para el óptimo es: {v_cost_hist[:,1].mean(axis=0)}\")\t\n",
    "print(f\"El costo promedio para la predicción es: {v_cost_hist[:,0].mean(axis=0)}\")\n",
    "print(f\"El costo promedio para el naive es: {v_cost_hist[:,2].mean(axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arq == 'FCNN':\n",
    "    v_cost_hist_FCNN = v_cost_hist.copy()\n",
    "    unf_hist_FCNN = unf_hist[:,0].copy()\n",
    "else:\n",
    "    v_cost_hist_GNN = v_cost_hist.copy()\n",
    "    unf_hist_GNN = unf_hist[:,0].copy()\n",
    "\n",
    "if arq == 'FCNN':\n",
    "    gap_percentages_hist_FCNN = gap_percentages_hist_pred.copy()\n",
    "else:\n",
    "    gap_percentages_hist_GNN = gap_percentages_hist_pred.copy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficas para informe (IMPORTANTE: correr las celdas de arriba para FCNN como GNN antes de correr lo de abajo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 subplots with histograms\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "axs[0].hist(v_cost_hist_FCNN[unf_hist_FCNN == 0,0] / v_cost_hist_FCNN[unf_hist_FCNN == 0,1], bins=30, range=(0.8, 1.2),alpha=0.8, label='FCNN/opt')\n",
    "axs[0].set_title(\"Pérdidas FCNN / pérdidas del óptimo\",fontsize=14)\n",
    "axs[0].grid()\n",
    "axs[0].set_xlabel(r'$MW/MW$',fontsize=12)\n",
    "axs[0].set_ylabel(\"Frecuencia\",fontsize=12)\n",
    "axs[0].set_xlim([0.8, 1.2])\n",
    "axs[0].set_ylim([0, 160])\n",
    "axs[1].hist(v_cost_hist_GNN[unf_hist_GNN == 0,0] / v_cost_hist_GNN[unf_hist_GNN == 0,1], bins=30, range=(0.8, 1.2), alpha=0.8, label='GNN/opt')\n",
    "axs[1].set_title(\"Pérdidas GNN / pérdidas del óptimo\",fontsize=14)\n",
    "axs[1].grid()\n",
    "axs[1].set_xlabel(r'$MW/MW$',fontsize=12)\n",
    "axs[1].set_ylabel(\"Frecuencia\",fontsize=12)\n",
    "axs[1].set_xlim([0.8, 1.2])\n",
    "axs[1].set_ylim([0, 160])\n",
    "axs[2].hist(v_cost_hist[unf_hist[:,2] == 0,2] / v_cost_hist[unf_hist[:,2] == 0,1], bins=30, range=(0.8, 1.2), alpha=0.8, label='v1/opt')\n",
    "axs[2].set_title(\"Pérdidas modelo básico / pérdidas del óptimo\",fontsize=14)\n",
    "axs[2].grid()\n",
    "axs[2].set_xlabel(r'$MW/MW$',fontsize=12)\n",
    "axs[2].set_ylabel(\"Frecuencia\",fontsize=12)\n",
    "axs[2].set_xlim([0.8, 1.2])\n",
    "axs[2].set_ylim([0, 160])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# # Plot the normalized histogram for pred\n",
    "# plt.title(\"Histograma de gaps en porcentaje para pred\")\n",
    "# plt.hist(gap_percentages_hist_pred, bins=10, alpha=0.5, density=True)  # Normalize the histogram\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the normalized histogram for opt\n",
    "# plt.title(\"Histograma de gaps en porcentaje para opt\")\n",
    "# plt.hist(gap_percentages_hist_opt, bins=10, alpha=0.5, density=True)  # Normalize the histogram\n",
    "# plt.show()\n",
    "\n",
    "bins = np.linspace(0, 7, 20)  # Creates 10 bins from 0 to 10\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Define consistent limits for the x and y axes\n",
    "# x_limits = (0, 6.5)\n",
    "# y_limits = (0, 36) \n",
    "x_limits = (0, 8)\n",
    "y_limits = (0, 60)\n",
    "\n",
    "# Plot the normalized histogram for pred FCNN\n",
    "axs[0].set_title(\"FCNN\", fontsize=14, fontweight='bold')\n",
    "axs[0].hist(gap_percentages_hist_FCNN, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_FCNN) / len(gap_percentages_hist_FCNN) * 100)  \n",
    "axs[0].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[0].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[0].set_xlim(x_limits)\n",
    "axs[0].set_ylim(y_limits)\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot the normalized histogram for pred GNN\n",
    "axs[1].set_title(\"GNN\", fontsize=14, fontweight='bold')\n",
    "axs[1].hist(gap_percentages_hist_GNN, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_GNN) / len(gap_percentages_hist_GNN) * 100) \n",
    "axs[1].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[1].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[1].set_xlim(x_limits)\n",
    "axs[1].set_ylim(y_limits)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[1].grid()\n",
    "\n",
    "# Plot the normalized histogram for opt\n",
    "axs[2].set_title(\"Óptimo\", fontsize=14, fontweight='bold')\n",
    "axs[2].hist(gap_percentages_hist_opt, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_opt) / len(gap_percentages_hist_opt) * 100)  \n",
    "axs[2].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[2].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[2].set_xlim(x_limits)\n",
    "axs[2].set_ylim(y_limits)\n",
    "axs[2].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[2].grid()\n",
    "\n",
    "# Plot the normalized histogram for v1\n",
    "axs[3].set_title(\"Modelo básico\", fontsize=14, fontweight='bold')\n",
    "axs[3].hist(gap_percentages_hist_v1, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_v1) / len(gap_percentages_hist_v1) * 100)  \n",
    "axs[3].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[3].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[3].set_xlim(x_limits)\n",
    "axs[3].set_ylim(y_limits)\n",
    "axs[3].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[3].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
