{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Julia version info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.8.1\n",
      "Commit afb6c60d69a (2022-09-06 15:09 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-linux-gnu)\n",
      "      Ubuntu 22.04.5 LTS\n",
      "  uname: Linux 6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2 x86_64 x86_64\n",
      "  CPU: 13th Gen Intel(R) Core(TM) i5-13400F: \n",
      "                 speed         user         nice          sys         idle          irq\n",
      "       #1-16  4623 MHz     119313 s         29 s      15046 s   44188529 s          0 s\n",
      "  Memory: 62.63290023803711 GB (46584.16796875 MB free)\n",
      "  Uptime: 277052.02 sec\n",
      "  Load Avg:  0.43  0.38  0.23\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-13.0.1 (ORCJIT, goldmont)\n",
      "  Threads: 1 on 16 virtual cores\n",
      "Environment:\n",
      "  HOME = /home/nacho\n",
      "  PATH = /home/nacho/miniconda3/envs/proy/bin:/home/nacho/.vscode-server/cli/servers/Stable-384ff7382de624fb94dbaf6da11977bba1ecd427/server/bin/remote-cli:/home/nacho/.local/bin:/home/nacho/miniconda3/envs/proy/bin:/home/nacho/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/nacho/julia-1.8.1/bin\n",
      "  TERM = xterm-color\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Julia executable: /home/nacho/julia-1.8.1/bin/julia\n",
      "[ Info: Trying to import PyCall...\n",
      "┌ Warning: PyCall is already installed.  However, you may have trouble using\n",
      "│ this Python executable because it is statically linked to libpython.\n",
      "│ \n",
      "│ For more information, see:\n",
      "│     https://pyjulia.readthedocs.io/en/latest/troubleshooting.html\n",
      "│ \n",
      "│ Python executable:\n",
      "│     /home/nacho/miniconda3/envs/proy/bin/python\n",
      "│ Julia executable:\n",
      "│     /home/nacho/julia-1.8.1/bin/julia\n",
      "└ @ Main ~/miniconda3/envs/proy/lib/python3.12/site-packages/julia/install.jl:90\n"
     ]
    }
   ],
   "source": [
    "# Generales\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandapower as pp\n",
    "import numpy as np\n",
    "import julia\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# julia\n",
    "julia.install()\n",
    "from julia.api import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "\n",
    "# Internos\n",
    "sys.path.append(os.path.abspath('../entrenamiento'))\n",
    "from src.arquitecturas import GNNUnsupervised, FCNNUnsupervised\n",
    "from src.Data_loader import load_net, load_data\n",
    "from src.utils import get_Ybus, get_Yline, init_lamdas,get_line\n",
    "from src.Loss import my_loss, get_max_min_values,cost_ploss, constraint_violation_power_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levantar Red electrica, Predictor y Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNUnsupervised(\n",
       "  (convs): ModuleList(\n",
       "    (0): TAGConv(3, 128, K=1)\n",
       "    (1-2): 2 x TAGConv(128, 128, K=1)\n",
       "    (3): TAGConv(128, 4, K=1)\n",
       "  )\n",
       "  (batchnorm): ModuleList(\n",
       "    (0-2): 3 x BatchNorm(15104)\n",
       "    (3): BatchNorm(472)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.010876351654157568, inplace=False)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = \"118\" # \"118\" o \"30\"\n",
    "arq = \"GNN\" # \"GNN\" o \"FCNN\"\n",
    "\n",
    "# Levantar CFG\n",
    "entrenamiento = \"best\"\n",
    "cfg = OmegaConf.load(f\"./runs/{red}/{arq}/\" + entrenamiento + \"/config.yaml\")\n",
    "weights_dir = f\"./runs/{red}/{arq}/\" + entrenamiento +  \"/weights/best_model.pt\"\n",
    "\n",
    "# Settear GPU\n",
    "torch.manual_seed(cfg.training.seed)\n",
    "device = cfg.training.device\n",
    "\n",
    "# Levantar red electrica\n",
    "edge_index, edge_weights, net = load_net(cfg.data.red,cfg.data.red_path,device)\n",
    "\n",
    "if red == \"30\":\n",
    "    net.line[\"max_loading_percent\"] *= 1.1\n",
    "    net.ext_grid[\"min_q_mvar\"] = -50\n",
    "else:\n",
    "    net.trafo.tap_pos = 0.0\n",
    "    net.bus.max_vm_pu = 1.1\n",
    "    net.bus.min_vm_pu = 0.9\n",
    "    net.line.max_i_ka /= 20\n",
    "\n",
    "pp.runpp(net)\n",
    "Y_bus = get_Ybus(net,device)\n",
    "Y_line = get_Yline(net,device)\n",
    "line = get_line(net, device)\n",
    "min_vector, max_vector = get_max_min_values(net,device)\n",
    "\n",
    "# Levantar Datos\n",
    "\n",
    "train_loader, val_loader, test_loader, norm_x = load_data(cfg.data.data_path, cfg.training.batch_size, cfg.data.normalize_X, cfg.data.red, device)# train_loader, val_loader, test_loader = load_data(cfg.data.data_path, cfg.training.batch_size, False, cfg.data.red,device)\n",
    "train_loader_unorm, val_loader_unorm, test_loader_unorm, _ = load_data(cfg.data.data_path, cfg.training.batch_size, False, cfg.data.red,device)\n",
    "\n",
    "# Levantar predictor\n",
    "num_layers = len(cfg.model.layers) - 1\n",
    "num_nodes = len(net.bus)\n",
    "try:\n",
    "    a = cfg.model.model\n",
    "except:\n",
    "    cfg.model.model = \"GNN\"\n",
    "if cfg.model.model==\"GNN\":\n",
    "        model = GNNUnsupervised(cfg.model.layers, edge_index, edge_weights, num_layers, cfg.model.K, min_vector, max_vector, num_nodes,cfg.model.dropout, batch_norm=cfg.training.batch_norm, use_edge_weights=cfg.training.use_edge_weights).to(device)\n",
    "elif cfg.model.model==\"FCNN\":\n",
    "    cfg.model.K = -1\n",
    "    model = FCNNUnsupervised(cfg.model.layers, edge_index, Y_bus, num_layers, cfg.model.K, min_vector, max_vector, num_nodes, cfg.model.dropout, batch_norm=cfg.training.batch_norm).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(weights_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir Salidas en Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor_test = torch.Tensor(np.load(f'../data/red{red}/test/vm_pu_opt.npy')).to(device)\n",
    "data_test = TensorDataset( y_tensor_test)\n",
    "test_loader_Y = DataLoader(data_test, batch_size=cfg.training.batch_size,drop_last=True)\n",
    "combined_dataloader = zip(test_loader, test_loader_Y)\n",
    "\n",
    "u_pred = []\n",
    "x_tot = []\n",
    "y_tot = []\n",
    "for input, y in combined_dataloader:\n",
    "    u_pred.append(model(input[0]).detach().cpu().numpy())\n",
    "    y_tot.append(y[0].detach().cpu().numpy())\n",
    "\n",
    "for input in test_loader_unorm:\n",
    "    x_tot.append(input[0].detach().cpu().numpy())\n",
    "\n",
    "# Concatenate in dim 0\n",
    "u_pred = np.concatenate(u_pred, axis=0)\n",
    "y_pred = u_pred[:,:,2][:,:,None]\n",
    "x_tot = np.concatenate(x_tot, axis=0)\n",
    "y_tot = np.concatenate(y_tot, axis=0)\n",
    "y_tot = y_tot[:,:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar desempeño como solucion del ORPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para evaluar pérdias y unfeasiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(net,tol=2e-3, percent_gap=None):\n",
    "    \n",
    "    # METRICA\n",
    "    Y_line_ij = np.asarray(net._ppc[\"internal\"][\"Yf\"].todense())\n",
    "    Y_line_ji = np.asarray(net._ppc[\"internal\"][\"Yt\"].todense())\n",
    "    V_mag = net.res_bus.vm_pu\n",
    "    delta = net.res_bus.va_degree\n",
    "    V = V_mag * np.exp(1j * delta * 2*np.pi/360)\n",
    "    V_lines_to = [V[x] for x in net.line.to_bus] + [V[x] for x in net.trafo.lv_bus]\n",
    "    V_lines_from = [V[x] for x in net.line.from_bus] + [V[x] for x in net.trafo.hv_bus]\n",
    "    ploss = (V_lines_from * np.conj(np.matmul(Y_line_ij,V)) + V_lines_to * np.conj(np.matmul(Y_line_ji,V))).real * net.sn_mva\n",
    "    ploss_cost = ploss.sum()\n",
    "    \n",
    "    \n",
    "    # UNFEASIBILITY\n",
    "    \n",
    "    ## Lineas\n",
    "    max_line = net.line.max_loading_percent.values.copy()\n",
    "    if percent_gap is not None:\n",
    "        max_line = max_line * (1 + percent_gap)\n",
    "    unfeas_line = (net.res_line.loading_percent.values > max_line + tol).sum()\n",
    "    gap_line_max = (net.res_line.loading_percent.values - net.line.max_loading_percent.values - tol)/(net.line.max_loading_percent.values - 0)\n",
    "    gap_line_max = gap_line_max[np.where(gap_line_max > 0)] * 100\n",
    "\n",
    "    ## Trafos\n",
    "    unfeas_trafo = 0\n",
    "    gap_trafo_max = []\n",
    "    if len(net.trafo) > 0:\n",
    "        max_trafo = net.trafo.max_loading_percent.values.copy()\n",
    "        if percent_gap is not None:\n",
    "            max_trafo = max_trafo * (1 + percent_gap)\n",
    "        unfeas_trafo = (net.res_trafo.loading_percent.values > max_trafo + tol).sum()\n",
    "        gap_trafo_max = (net.res_trafo.loading_percent.values - net.trafo.max_loading_percent.values - tol)/(net.trafo.max_loading_percent.values - 0)\n",
    "        gap_trafo_max = gap_trafo_max[np.where(gap_trafo_max > 0)] * 100\n",
    "    else:\n",
    "        unfeas_trafo = 0\n",
    "    \n",
    "    ## Voltajes\n",
    "    max_volt = net.bus.max_vm_pu.values.copy()\n",
    "    min_volt = net.bus.min_vm_pu.values.copy()\n",
    "    if percent_gap is not None:\n",
    "        max_volt +=  percent_gap*(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "        min_volt -= percent_gap*(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "    unfeas_volt = (net.res_bus.vm_pu.values < min_volt - tol).sum() + (net.res_bus.vm_pu.values > max_volt + tol).sum()\n",
    "    gap_volt_max = (net.res_bus.vm_pu.values - net.bus.max_vm_pu.values - tol)/(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "    gap_volt_max = gap_volt_max[np.where(gap_volt_max > 0)] * 100\n",
    "    gap_volt_min = (-net.res_bus.vm_pu.values + net.bus.min_vm_pu.values + tol)/(net.bus.max_vm_pu.values - net.bus.min_vm_pu.values)\n",
    "    gap_volt_min = gap_volt_min[np.where(gap_volt_min > 0)] * 100\n",
    "    \n",
    "    ## Q ext grid\n",
    "    max_q_extgrid = net.ext_grid.max_q_mvar.values.astype(float).copy()\n",
    "    min_q_extgrid = net.ext_grid.min_q_mvar.values.astype(float).copy()\n",
    "    if percent_gap is not None:\n",
    "        max_q_extgrid +=  percent_gap*(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "        min_q_extgrid -= percent_gap*(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "    unfeas_q_ext_grid = (net.res_ext_grid.q_mvar.values < min_q_extgrid - tol).sum() + (net.res_ext_grid.q_mvar.values > max_q_extgrid + tol).sum()\n",
    "    gap_q_ext_grid_max = (net.res_ext_grid.q_mvar.values - net.ext_grid.max_q_mvar.values - tol)/(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "    gap_q_ext_grid_max = gap_q_ext_grid_max[np.where(gap_q_ext_grid_max > 0)] * 100\n",
    "    gap_q_ext_grid_min = (-net.res_ext_grid.q_mvar.values + net.ext_grid.min_q_mvar.values + tol)/(net.ext_grid.max_q_mvar.values - net.ext_grid.min_q_mvar.values)\n",
    "    gap_q_ext_grid_min = gap_q_ext_grid_min[np.where(gap_q_ext_grid_min > 0)] * 100\n",
    "\n",
    "    # Agregar Todos\n",
    "    gaps_percentages = []\n",
    "    if len(gap_line_max) > 0:\n",
    "        gaps_percentages += list(gap_line_max)\n",
    "    if len(gap_trafo_max) > 0:\n",
    "        gaps_percentages += list(gap_trafo_max)\n",
    "    if len(gap_volt_max) > 0:\n",
    "        gaps_percentages += list(gap_volt_max)\n",
    "    if len(gap_volt_min) > 0:\n",
    "        gaps_percentages += list(gap_volt_min)\n",
    "    if len(gap_q_ext_grid_max) > 0:\n",
    "        gaps_percentages += list(gap_q_ext_grid_max)\n",
    "    if len(gap_q_ext_grid_min) > 0:\n",
    "        gaps_percentages += list(gap_q_ext_grid_min)\n",
    "        \n",
    "    if unfeas_line > 0 or unfeas_trafo > 0 or unfeas_volt > 0 or unfeas_q_ext_grid > 0:\n",
    "        unfeas = True\n",
    "    else:\n",
    "        unfeas = False\n",
    "    return ploss_cost, unfeas, [unfeas_line, unfeas_trafo, unfeas_volt, unfeas_q_ext_grid], gaps_percentages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar la función para datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_gens = net.gen.bus.values.astype(int)\n",
    "idx_load = net.load.bus.values.astype(int)\n",
    "\n",
    "v_cost_hist = []\n",
    "unf_hist = []\n",
    "unf_cont_hist = []\n",
    "gap_percentages_hist_pred = []\n",
    "gap_percentages_hist_opt = []\n",
    "gap_percentages_hist_v1 = []\n",
    "\n",
    "\n",
    "percent_gap = 0.0 ## GAPS PARA TOLERANCIA MAXIMA\n",
    "\n",
    "for idx in range(np.shape(x_tot)[0]):\n",
    "    # Cargar entradas\n",
    "    net.load.loc[:,'p_mw'] = x_tot[idx,idx_load,0]* 100\n",
    "    net.load.loc[:,'q_mvar'] = x_tot[idx,idx_load,1]* 100\n",
    "    net.gen.loc[:,'p_mw'] =  x_tot[idx,idx_gens,2]* 100\n",
    "    \n",
    "    # Cargar solucion predicha\n",
    "    net.gen.vm_pu = y_pred[idx,idx_gens,0]\n",
    "    pp.runpp(net, enforce_q_lims=True)\n",
    "    v_cost_pred, unf_pred, unf_const_pred, gaps_percentages_pred = get_stats(net,percent_gap=percent_gap)\n",
    "\n",
    "    # Cargar solución naive\n",
    "    net.gen.vm_pu = 1\n",
    "    pp.runpp(net, enforce_q_lims=True)\n",
    "    v_cost_v1, unf_v1, unf_const_v1, gaps_percentages_v1  = get_stats(net,percent_gap=percent_gap)\n",
    "    \n",
    "    # Cargar solución óptima\n",
    "    net.gen.vm_pu = y_tot[idx,idx_gens,0]\n",
    "    pp.runpp(net, enforce_q_lims=True)\n",
    "    v_cost_opt, unf_opt, unf_const_opt, gaps_percentages_opt  = get_stats(net,percent_gap=percent_gap)\n",
    "    \n",
    "    # Guardar todo\n",
    "    v_cost_hist.append([v_cost_pred, v_cost_opt,v_cost_v1])\n",
    "    unf_hist.append([unf_pred, unf_opt, unf_v1])\n",
    "    unf_cont_hist.append([unf_const_pred, unf_const_opt, unf_const_v1])\n",
    "    gap_percentages_hist_pred += gaps_percentages_pred\n",
    "    gap_percentages_hist_opt += gaps_percentages_opt\n",
    "    gap_percentages_hist_v1 += gaps_percentages_v1\n",
    "\n",
    "\n",
    "v_cost_hist = np.array(v_cost_hist)\n",
    "unf_hist = np.array(unf_hist)\n",
    "unf_cont_hist = np.array(unf_cont_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de factibles para el óptimo es: 0.96875\n",
      "El porcentaje de factibles para la predicción es: 1.0\n",
      "El porcentaje de factibles para el naive es: 0.9609375\n"
     ]
    }
   ],
   "source": [
    "print(f\"El porcentaje de factibles para el óptimo es: {1 - unf_hist[:,1].mean(axis=0)}\")\n",
    "print(f\"El porcentaje de factibles para la predicción es: {1 - unf_hist[:,0].mean(axis=0)}\")\n",
    "print(f\"El porcentaje de factibles para el naive es: {1 - unf_hist[:,2].mean(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El costo promedio para el óptimo es: 84.82884076595995\n",
      "El costo promedio para la predicción es: 84.05896274886392\n",
      "El costo promedio para el naive es: 95.9575905733169\n"
     ]
    }
   ],
   "source": [
    "print(f\"El costo promedio para el óptimo es: {v_cost_hist[:,1].mean(axis=0)}\")\t\n",
    "print(f\"El costo promedio para la predicción es: {v_cost_hist[:,0].mean(axis=0)}\")\n",
    "print(f\"El costo promedio para el naive es: {v_cost_hist[:,2].mean(axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arq == 'FCNN':\n",
    "    v_cost_hist_FCNN = v_cost_hist.copy()\n",
    "    unf_hist_FCNN = unf_hist[:,0].copy()\n",
    "else:\n",
    "    v_cost_hist_GNN = v_cost_hist.copy()\n",
    "    unf_hist_GNN = unf_hist[:,0].copy()\n",
    "\n",
    "if arq == 'FCNN':\n",
    "    gap_percentages_hist_FCNN = gap_percentages_hist_pred.copy()\n",
    "else:\n",
    "    gap_percentages_hist_GNN = gap_percentages_hist_pred.copy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficas para informe (IMPORTANTE: correr las celdas de arriba para FCNN como GNN antes de correr lo de abajo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 subplots with histograms\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "axs[0].hist(v_cost_hist_FCNN[unf_hist_FCNN == 0,0] / v_cost_hist_FCNN[unf_hist_FCNN == 0,1], bins=30, range=(0.8, 1.2),alpha=0.8, label='FCNN/opt')\n",
    "axs[0].set_title(\"Pérdidas FCNN / pérdidas del óptimo\",fontsize=14)\n",
    "axs[0].grid()\n",
    "axs[0].set_xlabel(r'$MW/MW$',fontsize=12)\n",
    "axs[0].set_ylabel(\"Frecuencia\",fontsize=12)\n",
    "axs[0].set_xlim([0.8, 1.2])\n",
    "axs[0].set_ylim([0, 160])\n",
    "axs[1].hist(v_cost_hist_GNN[unf_hist_GNN == 0,0] / v_cost_hist_GNN[unf_hist_GNN == 0,1], bins=30, range=(0.8, 1.2), alpha=0.8, label='GNN/opt')\n",
    "axs[1].set_title(\"Pérdidas GNN / pérdidas del óptimo\",fontsize=14)\n",
    "axs[1].grid()\n",
    "axs[1].set_xlabel(r'$MW/MW$',fontsize=12)\n",
    "axs[1].set_ylabel(\"Frecuencia\",fontsize=12)\n",
    "axs[1].set_xlim([0.8, 1.2])\n",
    "axs[1].set_ylim([0, 160])\n",
    "axs[2].hist(v_cost_hist[unf_hist[:,2] == 0,2] / v_cost_hist[unf_hist[:,2] == 0,1], bins=30, range=(0.8, 1.2), alpha=0.8, label='v1/opt')\n",
    "axs[2].set_title(\"Pérdidas modelo básico / pérdidas del óptimo\",fontsize=14)\n",
    "axs[2].grid()\n",
    "axs[2].set_xlabel(r'$MW/MW$',fontsize=12)\n",
    "axs[2].set_ylabel(\"Frecuencia\",fontsize=12)\n",
    "axs[2].set_xlim([0.8, 1.2])\n",
    "axs[2].set_ylim([0, 160])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# # Plot the normalized histogram for pred\n",
    "# plt.title(\"Histograma de gaps en porcentaje para pred\")\n",
    "# plt.hist(gap_percentages_hist_pred, bins=10, alpha=0.5, density=True)  # Normalize the histogram\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the normalized histogram for opt\n",
    "# plt.title(\"Histograma de gaps en porcentaje para opt\")\n",
    "# plt.hist(gap_percentages_hist_opt, bins=10, alpha=0.5, density=True)  # Normalize the histogram\n",
    "# plt.show()\n",
    "\n",
    "bins = np.linspace(0, 7, 20)  # Creates 10 bins from 0 to 10\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Define consistent limits for the x and y axes\n",
    "# x_limits = (0, 6.5)\n",
    "# y_limits = (0, 36) \n",
    "x_limits = (0, 8)\n",
    "y_limits = (0, 60)\n",
    "\n",
    "# Plot the normalized histogram for pred FCNN\n",
    "axs[0].set_title(\"FCNN\", fontsize=14, fontweight='bold')\n",
    "axs[0].hist(gap_percentages_hist_FCNN, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_FCNN) / len(gap_percentages_hist_FCNN) * 100)  \n",
    "axs[0].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[0].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[0].set_xlim(x_limits)\n",
    "axs[0].set_ylim(y_limits)\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot the normalized histogram for pred GNN\n",
    "axs[1].set_title(\"GNN\", fontsize=14, fontweight='bold')\n",
    "axs[1].hist(gap_percentages_hist_GNN, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_GNN) / len(gap_percentages_hist_GNN) * 100) \n",
    "axs[1].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[1].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[1].set_xlim(x_limits)\n",
    "axs[1].set_ylim(y_limits)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[1].grid()\n",
    "\n",
    "# Plot the normalized histogram for opt\n",
    "axs[2].set_title(\"Óptimo\", fontsize=14, fontweight='bold')\n",
    "axs[2].hist(gap_percentages_hist_opt, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_opt) / len(gap_percentages_hist_opt) * 100)  \n",
    "axs[2].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[2].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[2].set_xlim(x_limits)\n",
    "axs[2].set_ylim(y_limits)\n",
    "axs[2].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[2].grid()\n",
    "\n",
    "# Plot the normalized histogram for v1\n",
    "axs[3].set_title(\"Modelo básico\", fontsize=14, fontweight='bold')\n",
    "axs[3].hist(gap_percentages_hist_v1, bins=bins, alpha=0.8, weights=np.ones_like(gap_percentages_hist_v1) / len(gap_percentages_hist_v1) * 100)  \n",
    "axs[3].set_xlabel(\"Porcentaje de violación\", fontsize=14)\n",
    "axs[3].set_ylabel(\"Porcentaje de ocurrencia\", fontsize=14)\n",
    "axs[3].set_xlim(x_limits)\n",
    "axs[3].set_ylim(y_limits)\n",
    "axs[3].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[3].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
